{"CSCI 2021": [["Lecture 2/16", "{\"input\":\"*printf(\\\"%.4e\\\", x) print with scientific notation\\n*Mantissa \\\\(\\\\equiv\\\\) Significand \\\\(\\\\equiv\\\\) Fractional part: this is all to the right of .\\n*111.01011 is ex where 01011 is fractional part\\n*IBM 32 btis, 1-bit sign, 7-bit exponent, 24-but significand\\n*IEEE 754 Floating Point Standard\\n**32 bit float, 64 bit double\\n**Used by modern manufactureres\\n**1 it for sign, 8/11 bits for exponent, 23/52 bits for fractional part 7.22/15.95 decimal digits of accuracy (float/double)\\n*Three categories of floats\\n**Normalized: most common like 1.0 and -9.56e37\\n**Denormalized: very close to 0.0\\n**Extreme or error values: like NAN of infinity\\n*\",\"code\":{}}"], ["Lecture 2/7", "{\"input\":\"<h1 >Integer types</h1>\\n*0b10101 = binary 10101\\n*0x7D = hex 7D\\n*0175 = octal 175\\n*7 bit for char so first bit is always 0 for ASCII\\n*Addition of bits works the same as in base 10\\n*For two's compliment, most significant bit is -128\\n*1111 1111 is -1\\n*~ is inversion operator for binary\\n*To negate, invert and add 1, that is what y = -x does in C\\n\\n\",\"code\":{}}"], ["Lecture 2/4", "{\"input\":\"*continue is used to break iteration of loop and go to net\\n*goto: cod:c_cpp,goto Don't really use this\\n*Switch: prefer if then cod:c_cpp,switch\\n*start number with 0b makes c read it as binary like Ob11010\\n*0x works with hex and 0 for Octal\",\"code\":{\"goto\":\"place:\\n    printf(\\\"hi\\\");\\n    \\ngoto place;\",\"gotoD\":\"\",\"gotoDo\":\"\",\"gotoDon\":\"\",\"gotoDo=\":\"\",\"gotoDo==\":\"\",\"gotoDo===\":\"\",\"switch\":\"switch(c) {\\n    case 1:\\n        printf(\\\"\\\");\\n        break\\n    default:\\n        printf(\\\"A\\\");\\n        break;\\n}\"}}"], ["Lecture 2/2", "{\"input\":\"*Structs have fields\\n*If using ptr = malloc(size * n), the ptr can can be changes with ptr[i] for 0 < i < n\\n*fscanf returns number of tokens parsed\\n*fread and fwrite can be used for byte files\",\"code\":{}}"], ["Lectrue 2/14", "{\"input\":\"*Arithmetic and Logic Unit (ALU) does integer ops in machine\\n*|| is logical or\\n*| is bitwise or\\n*&& is logical and\\n*& is bitwise and\\n*^ is bitwise exclusive or\\n*! is logical not\\n*~ is bitwise not/invert\\n*shifts can be used for more efficient and division of powers of 2\\n\\ncod:c_cpp,shift\",\"code\":{\"a\":\"\",\"co\":\"\",\"c\":\"\",\"s\":\"\",\"sh\":\"\",\"shi\":\"\",\"shift\":\"x = y << k; //left shift k bits\\nx = y >> k; //right shift k bits. If signed and most sig bit is 1, 1s are added. Otherwise add 0s\"}}"], ["Chapter 2", "{\"input\":\"*Hexadecimal to binary by continuing to divide by 16. Remainder is the next hex char\\n*word size = computer's size of pointer\\n*If w is word size, there can be at most \\\\( 2^w - 1 \\\\) addresses\\n*gcc -m32 prog.c compiles for 32 bit\\n*long unsigned int etc don't have to be in order\\n*Big endian is left to right like in hex but little endian is opposite\\n*Bit operations: cod:c_cpp,bits\\n*x << k x is shifted k bits left, can do x << y << k to also shift y. Right shift not well defined. Associate left to right. Shifting left drops k most sig digits and adds k 0s to right\\n*long is  different if 32 or 64 bit\\n*Convert from signed to unsigned: cod:c_cpp,convert\\n*For signed to unsigned, if num is neg then take num + 2^w\\n*For unsigned to signed, if num is greater than signed max use num - 2^w\\n*123u makes unsigned \\n*C doesn't decide how to represent signed, machine does\\n*To convert unsigned to larger data type add leading 0s this is zero extention\\n*To extend 2s compliment add most sig bit\\n*To truncate unsigned number, drop most sig bits\\n*To truncate 2s compliment, \",\"code\":{\"bits\":\"a = 0110\\nb = 1100\\na & b = 0100 //intersect\\na | b = 1110 //or\\na ^ b = 1010 //exclusive or\\n~b = 0011\",\"convert\":\"short int v = -12345;\\nunsigned short uv = (unsigned short) v;\"}}"], ["Exam 1 Notes", "{\"input\":\"*char = 1 byte\\n*short = 2 bytes\\n*int = 4 bytes\\n*long = 8 bytes\\n*float = 4 bytes\\n*double = 8 bytes\\n*pointer = 8 bytes\\n*0 = false\\n*pointer of type void has no type and removes type checks (have to cast)\\n*can +/- a pointer to move up or down\\n*Bare name references starting address of array\\n4 layers of memory:\\n\\n\\n1. Stack: automatic, push/pop\\nwith function calls\\n2. Heap: malloc() and free()\\n3. Global: variables outside\\nfunctions, static vars\\n4. Text: Assembly instructions\\n\\n*structs group data\\n*File stuff :cod:c_cpp,files\\n*Ternary operators: cod:c_cpp,tern\\n*In order to convert from base 10 to base 2, repeatedly divide by 2, the remainder is the bit. Do this until division yields 0\\n*Hexadecimal is 0 to 15\\n*byte is 2 hex digits\\n*When there is a bit overflow, excess sig bits are dropped (ie drop biggest bit)\\n*for unsigned arithmetic, if value goes negative add extra bit in front of what is having a subtraction done to \",\"code\":{\"files\":\"FILE *fopen(char *fname, char *mode);\\n// open file named fname, mode is \\\"r\\\" for reading, \\\"w\\\" for writing\\n// returns a File Handle (FILE *) on success\\n// returns NULL if not able to open file; do not fclose(NULL)\\n\\nint fclose(FILE *fh);\\n// close file associated with fh, writes pending data to file,\\n// free()'s memory associated with open file\\n// Do not fclose(NULL)\\n\\nint fscanf(FILE *fh, char *format, addr1, addr2, ...);\\n// read data from an open file handle according to format string\\n// storing parsed tokens in given addresses returns EOF if end of file\\n// is reached\\n\\nint fprintf(FILE *fh, char *format, arg1, arg2, ...);\\n// prints data to an open file handle according to the format string\\n// and provided arguments\\n\\nvoid rewind(FILE *fh);\\n// return the given open file handle to the beginning of the file\\n\\nsize_t fread(void *dest, size_t byte_size, size_t count, FILE *fh);\\n// read binary data from an open file handle. Attempt to read\\n// byte_size*count bytes into the buffer pointed to by dest.\\n// Returns number of bytes that were actually read\\n\\nsize_t fwrite(void *src, size_t byte_size, size_t count, FILE *fh);\\n// write binary data to an open file handle. Attempt to write\\n// byte_size*count bytes from buffer pointed to by src.\\n// Returns number of bytes that were actually written\",\"tern\":\"double x = 9.95;\\nint y = (x < 10.0) ? 2 : 4; \\n                     t.  f\"}}"], ["2.4 Book Notes", "{\"input\":\"*Round-to-even\\n*Round-toward-zero\\n*Round-down\\n*Round-up\",\"code\":{}}"], ["Ch 3 Book", "{\"input\": \"\", \"code\": {}}"], ["Lecture 2/25", "{\"input\": \"\", \"code\": {}}"], ["Lecture 3/2", "{\"input\":\"*rip register points to next instruction\\n**manipulating this can do a jump ie a conditional\\n*FLAGS register stores conditionals\\n*cmp results stored in FLAGS, jmp says to jump is equal, not equal, less, etc\\n*Conditions are often flipped by compiler\",\"code\":{}}"], ["Lecture 3/30", "{\"input\":\"*cram is less common because expensive\\n*dram is more space efficient \\n*\",\"code\":{}}"], ["Chapter 4", "{\"input\":\"\",\"code\":{}}"]], "CSCI 2041": [["Lecture 2/7", "{\"input\":\"*referential transparency: If expression can be replaced with its value without affecting behavior of program\\n*Opposite is referentially opaque like ++x in C\\n*let add = fun x -> (fun y -> x + y) in 2 * (add 3) (5+5)\\n\\nS1.4 #1\\n\\n'''\\nlet x = 1 + 2 in let y = x + 3 in x + y\\nlet x = 3 in let y = x + 3 in x + y\\nlet x = 3 in let y = 3 + 3 in 3 + y\\nlet y = 6 in 3 + y\\n3 + 6\\n9\\n'''\\n\\nS1.4 #2\\n\\n'''\\n1 + sum (2 :: 3 :: [])\\n1 + (2 + sum (3 :: []))\\n1 + (2 + ( 3 + sum ([])))\\n1 + (2 + ( 3 + 0)) \\n1 + (2 + 3)\\n1 + 5\\n6\\n'''\\n\",\"code\":{}}"], ["Lecture 2/9", "{\"input\":\"Assert:\\ncod:ocaml,assert\\nLambda expessions: cod:ocaml,lambda\\nOperators as functions: cod:ocaml,oaf\",\"code\":{\"assert\":\"let _ =\\n    assert(funct param = out);\\n    assert(...);\",\"la\":\"\",\"lam\":\"\",\"lamb\":\"\",\"lambd\":\"\",\"lambda\":\"fun x y -> x=y\",\"o\":\"\",\"oa\":\"\",\"oaf\":\"(+) a b\\n( * ) a b (*Space because of comments**)\\n(-) a b\\n(/) a b\\n(<=) a b\"}}"], ["Lecture 2/4", "{\"input\":\"*Can do <mark style=\\\"background-color:orange;\\\">let (x,y) = something n in x + y</mark>\\n*Can take function as param\\ncod:ocaml,12\\n\\ncod:ocaml,13\\ncod:ocaml,14\\ncod:ocaml,15\",\"code\":{\"1\":\"\",\"12\":\"type fraction = int * int\",\"13\":\"let add (r1: fraction) (r2: fraction) : fraction = \\n    let (r1n, r1d) = r1 in\\n    let (r2n, r2d) = r2 in\\n    (r1n * r2d + r1d + r2n, r1d + r2d)\",\"14\":\"let rec lookup_all (key: string) (lst: (string * int) list) : int list = \\n    match lst with\\n    | [] -> []\\n    | h :: t -> \\n        let (k, v) = h in\\n        if k == key\\n        then v :: lookup_all key t\\n        else lookup_all key t\",\"15\":\"let rec fib (x: int) : int = \\n    match x with\\n    | 0 -> 0\\n    | 1 -> 1\\n    | _ -> fib (x - 1) + fib (x - 2)\"}}"], ["Lecture 2/11", "{\"input\":\"cod:ocaml,code\\n\\n*map func lst does function to all elements of list\\n*parametric polymorphism \\n*Lambda functions common with map\\n*currying converts multiple args into multiple funcs each with one arg \\n*filter func lst filter lst by func\\n*fold (+) 0 xs collapses list to one val\\n\",\"code\":{\"code\":\"let flip f a b = f b a\\n(*type of flip is flip : ('a' -> 'b -> 'c') -> 'b -> 'a -> 'c'  **)\\n\\nlet compose f g x = g f x\\n\\nmap is of type: \\n(* ('a -> 'b) -> 'a list -> b' list **)\\n\\nlet rec map (f: 'a -> 'b) (lst: 'a list) : 'b list =\\n    match lst with\\n    | [] -> []\\n    | h :: t -> f h :: map f t\\n    \\nlet lower (lst: char list) : char list = \\n    let clean c = not (c = \\\"A\\\" || c = \\\"B\\\" || c = \\\"C\\\" || c = \\\"D\\\")\\n    in filter clean lst\\n\"}}"], ["Lecture 2/14", "{\"input\":\"cod:ocaml,fold\",\"code\":{\"fold\":\"let rec fold (f: 'a-> 'b-> 'b)  (lst: 'a list) (v: 'b) : 'b =\\n    match lst with\\n    | [] -> v\\n    | h::t -> f h (fold h t v)\\n    \\nlet rec foldl (f: 'b -> 'a -> 'b) (v: 'b) (lst: 'a lsit) : 'b  = \\n    match lst with\\n    | [] -> v\\n    | h::t -> fold f (f v h) t\"}}"], ["Quiz 1 Prep", "{\"input\":\"*Has garbage collection\\n*2 compilers. 1 makes byte code for virtual machine, other native machine code\\n*^ concats string\\n*When function fails is it incomplete/non-total\\n*list is like [1; 2; 3;]\\n*Tuples are called product types\\n*Tuples are type1 * type2\\n*cod:ocaml,tuples\\n*Some errors like division by 0 are detected at runtime\\n*strong = program never execute type-incorrect operation or invalid memory access\\n*static = this is checked before the program runs.\\n*safe = strong, static type system\\n*Lists are inductive data structures\",\"code\":{\"t\":\"\",\"tu\":\"\",\"tup\":\"\",\"tupp\":\"\",\"tuppe\":\"\",\"tuppel\":\"\",\"tuppels\":\"\",\"tuple\":\"\",\"tuples\":\"let add_pair ( p : int * int ) : int =\\n    match p with\\n    | ( n1 , n2 ) -> n1 + n2\\n    \\nlet add_pair_v2 ( p : int * int ) : int =\\n    let ( n1 , n2 ) = p in n1 + n2\"}}"], ["Ch 3 book", "{\"input\":\"<h2>Variants:</h2>\\ncod:ocaml,variants\\n*failwith \\\"msg\\\" will raise failure\\n<h2>Records</h2>\\ncod:ocaml,records\\n<h2>Type Synonyms</h2>\\nCan be used to reference an already defined type ex: cod:ocaml,syn\\n<h2>Options</h2>\\nCan be used in the case that you may return nothing ex: cod:ocaml,options\\nAn association list is not built in, but is a list of pairs. Like a dictionary\\n\",\"code\":{\"variants\":\"type day = Sun | Mon | Tue | Wed | Thu | Fri | Sat\\nlet d = Tue\\n(* val d : day = Tue **)\",\"records\":\"type mon = {name : string; hp : int; ptype : ptype}\\n\\nlet c = {name = \\\"Charmander\\\"; hp = 39; ptype = TFire};;\\n\\nmatch c with {name = n; hp = h; ptype = t} -> h\",\"syn\":\"type point = float * float\\ntype vector = float list\\ntype matrix = float list list\",\"options\":\"let rec list_max = function\\n  | [] -> None\\n  | h :: t -> begin\\n      match list_max t with\\n        | None -> Some h\\n        | Some m -> Some (max h m)\\n      end\\n      \\nval list_max : 'a list -> 'a option = <fun>\"}}"], ["Lecture 2/28", "{\"input\":\"<h1>Modularity</h1>\\n*Can use open then just refer contents of other file\\n*Can use File.funct without open make sure file name is capitalized\\n*mli is an interface file: tells you what you can see in file. Says types\\n*Signature Syntax: module type name = sig STUFF end\\n*Can have one signature with multiple versions of module\\n*can make reference to module like module x = name\\n*Primary type in signature is often named t\\n*Modules inside a file are given suffix M\\n*Signatures within file are given suffix S\\n*functors are parameterized modules\\n**Say you depend on module like Stack, but let user make the Stack\\n**Take module as input and give module as output\\n**cod:ocaml,functor\\n*ocamlbuild file.byte complies to virtual machine byte code\\n*ocamlbuild file.native compliles to machine code\\n*In utop use #mod_use \\\"file\\\" ;;\",\"code\":{\"functor\":\"module functorName (moduleName: signature) : newSignature = struct\\n\\n\\nend\\n\\n(* Example ***)\\nopen expr\\nlet \"}}"], ["Lecture 2/25", "{\"input\":\"<h2>Disjoint Unions</h2>\\ncod:ocaml,dj\\n\\n*unit type only has one value written as ()\\n*; is an operator of type unit -> 'a -> 'a\\n*type abrevs: type x = int\\n\\ncod:ocaml,exercises\",\"code\":{\"dj\":\"type msg = StringMsg of String * int\\n        | BoolMsg of bool * int\\n        | FloatMsg of float * int\",\"exercises\":\"type weekday = Mon | Tue | Wed | Thurs | Fri | Sat | Sun\\n\\nlet isWorkDay (day: weekday) : bool =\\n    match day with\\n    | Mon | Tue | Wed | Thurs | Fri -> true\\n    | Sat | Sun -> false\\n    \\ntype circ_desc = coord * float\\ntype tri_desc = coord * coord * coord\\ntype sqr_desc = coord * coord * coord * coord\\n\\ntype shape = Circle of circ_dec\\n            | Triange of tri_desc\\n            | Square of sqr_desc\\n            \\nlet isRect (s: shape) : bool =\\n    match s with\\n    | Square _ -> true\\n    | _ -> false\"}}"], ["Ch 4 Notes", "{\"input\":\"<h2>Map</h2>\\n*To do tail recursive (return backwards) use rev_map\\n*Tail recursive happens when last return returns value of recursive call\\n<h2>Fold</h2>\\n*Fold left\\n**- : ('a -> 'b -> 'a) -> 'a -> 'b list -> 'a = fun\\n*Fold right\\n**- : ('a -> 'b -> 'b) -> 'a list -> 'b -> 'b = fun\",\"code\":{}}"], ["Lecture 3/4", "{\"input\":\"\",\"code\":{}}"], ["Lecture 3/30", "{\"input\":\"S5 #3\\n1. How to do operations on booleans\\n\\nS5 #4\\n1. expr -> string list\\n2. Some intresting cases\",\"code\":{\"and\":\"S5 #3\\n\"}}"], ["Lecture 3/28", "{\"input\":\"S5 #1\\n\\n1. 2 + 9 = 11\\n2. 1 + 3 * 2 = 7\\n3. (4+5) * 3 = 27\\n\\nS5 #2\\ncod:ocaml,ts\",\"code\":{\"ts\":\"let rec string_of_expr (e: expr) : string =\\n    match e with\\n    | Add (l, r) -> \\\"(\\\" ^ string_of_expr l ^ \\\"+\\\" ^ string_of_expr r ^ \\\")\\\"\\n    | Sub (l, r) -> \\\"(\\\" ^ string_of_expr l ^ \\\"-\\\" ^ string_of_expr r ^ \\\")\\\"\\n    | Mul (l, r) -> \\\"(\\\" ^ string_of_expr l ^ \\\"*\\\" ^ string_of_expr r ^ \\\")\\\"\\n    | Div (l, r) -> \\\"(\\\" ^ string_of_expr l ^ \\\"/\\\" ^ string_of_expr r ^ \\\")\\\"\\n    | Num n -> Int.to_string n\"}}"], ["Lecture 4/1", "{\"input\": \"\", \"code\": {}}"], ["Lecture 4/13", "{\"input\":\"<h2>Red and Black Trees</h2>\\n*No red node has red child\\n*all paths from root have same name of black nodes\\n*Shortest is only black nodes\\n*Longest path alternates red and black\",\"code\":{}}"], ["Lecture 4/4", "{\"input\":\"*Reference is used so that something can never be null \\n*Unit is like void \\n*Imperative programming has assignments and loops\",\"code\":{}}"], ["Lecture 4/8", "{\"input\":\"*Tail recursion can be compiled into a loop\\n*Persistent is when data doesn't change\\n**List append is persistent\\n*Sharing via pointers\\n*Tail recursion is when no more work to do once returned from recursion\\n\\nExercise S7.1: #1\\ncod:ocaml,s71\",\"code\":{\"s71\":\"let rec suffixes (lst: 'a list) : 'a list list =\\n    match lst with\\n    | [] -> [[]]\\n    | x :: xs -> lst :: suffixes xs\"}}"], ["Lecture 4/11", "{\"input\": \"\", \"code\": {}}"]], "STAT 3022": [["Lecture 2/2", "{\"input\":\"<h1 >Inference about the Slope</h1>\\n*t test for Population Slope: is there linear relationship?\\n* \\\\( H_o: \\\\beta_1 = 0\\\\),  \\\\( H_a: \\\\beta_1 \\\\neq 0 \\\\)\\n*test stat  \\\\( t = \\\\frac{b_1 - \\\\beta_1}{ S_{b_1} } \\\\) where  \\\\( S_{b_1} = \\\\frac{S_{YX}}{\\\\sqrt{ \\\\sum_{i=1}^n (X_i - \\\\bar{X})^2 }} \\\\) this is the standard error\\n*df = n - 2\\n*p value is the probability of observing extreme value when null hypothesis is true\\n*\\\\( \\\\alpha\\\\) is significance level\\n*Reject null when  \\\\( p < \\\\alpha \\\\)\\nSignificance of the overall parameters\\n*null is that the model is not adequate, alternate is adequate\\n*Use F test for this\\n*Percent of how adequate the model is Multiple R-Squared, this is percentage deviation in response model was able to explain\\n*Anova does F test\\n<h1 >Correlation Analysis</h1>\\n\",\"code\":{}}"], ["Lecture 2/7", "{\"input\":\"*Residual sum of squares is sum of resids squared = RSS\\n*SST = SSreg + RSS\\n*SSreg = variation of y explained by model,  RSS is not explained, SST is total\\n*sum of squares of actual - mean = sos of predicted - mean + sos actual - predicted\\n* \\\\(R^2 = \\\\frac{SSreg}{SST} = 1 - \\\\frac{RSS}{SST}\\\\)  = estimated correlation\\n* Sample variance =  \\\\( \\\\frac{\\\\sum_{i=1}^n (y_i-\\\\bar{y})^2}{n-1} \\\\)\\n*F test between intercept model vs full model\\n*n-2 degs freedom\\n*Null is slope 0, alternate is not 0\\n*F= SSreg/1 / RSS/(n-2)\",\"code\":{}}"], ["Lecture 2/4", "{\"input\": \"\", \"code\": {}}"], ["Lecture 2/11", "{\"input\":\"*Traditional R^2 only handles fitness, adjusted takes fitness and model complexity\\n*R^2 not as useful with more params\\n*For categorical binary, use 1 and 0\\n*primary variable of interest, there are also covariates\",\"code\":{}}"], ["Ch 2 Book", "{\"input\":\"*Slope of LSR is estimate of population slope\\n*T test for slope\\n**\\\\(t = \\\\frac{\\\\hat{\\\\beta_1}}{SE_{\\\\hat{\\\\beta_1}}}\\\\)\\n**n-2 degrees of freedom\\n*Confidence interval for slope is \\\\(\\\\hat{\\\\beta_1} \\\\pm t * SE_{\\\\hat{\\\\beta_1}}\\\\)\\n*t* is critical value for \\\\(t_{n-2}\\\\) distribution\\n*ANOVA is analysis of variance\\n**\\\\(y - \\\\bar{y} = (\\\\hat{y} - \\\\bar{y}) + (y - \\\\hat{y})\\\\), SSTotal = SSModel + SSE\",\"code\":{}}"], ["CH 2 Notes COnt", "{\"input\":\"*\\\\(F = \\\\frac{MSModel}{MSE}, MSE=\\\\frac{SSE}{n-2}\\\\)\\n*F Test checks if slope is significant\\n*\\\\(r^2 = 1- \\\\frac{SSE}{SSTotal}\\\\)\\n*\\\\(Slope = r\\\\frac{S_y}{S_x}\\\\)\\n*Can test r with t test\\n**\\\\(t = \\\\frac{r\\\\sqrt{n-2}}{\\\\sqrt{1-r^2}}\\\\)\\n**n-2 degrees of freedom\\n**\\\\(\\\\rho = 0\\\\) is null where \\\\(\\\\rho\\\\) is population correlation\\n*Practically vs Statistically Significant\\n*Confidence interval: \\\\(\\\\hat{y} \\\\pm t*SE_{\\\\hat{\\\\mu}}\\\\)\\n*Prediction interval: \\\\(\\\\hat{y} \\\\pm t*SE_{\\\\hat{y}}\\\\)\\n*t* is the critical value n-2 degrees of freedom\\n\",\"code\":{}}"], ["Ch 1 Book", "{\"input\":\"*Data = Model + Error\\n*Hat = estimates fitted\\n* \\\\(\\\\beta\\\\) is often used as param\\n*Residual = observed - predicted\\n*SSE = sum of sqaured errors\\n*Assumptions: Linearity, mean of error is centered at 0, uniform spread, errors are independent, model follows normal dist, and randomness\\n*If E is error, above can be summarized as  \\\\(E \\\\approx N(0, sd_E)\\\\) and errors are independent\\n*Standard error of regression is typical error and is  \\\\(\\\\sqrt{\\\\frac{SSE}{n-2}}\\\\)\\n*Residual vs fitted shows linearity and constant variance. Want no pattern\\n*Normal quantile plot and normal probability plot can prove normality if linear. Basically normal vs observation\\n*Outlier if resid / sd of regression >= 2. This is standardized resid\\n*Point has a lot of leverage when it greatly influences model\\n\",\"code\":{}}"], ["Lecture 2/16", "{\"input\":\"*Second order polynomial in one var: \\\\(y = \\\\beta_0 + \\\\beta_1x + \\\\beta_2x^2 + error\\\\)\\n*Second order polynomial in two vars: \\\\(y = \\\\beta_0 + \\\\beta_1x_1 + \\\\beta_2x_2 + \\\\beta_{11}x_1^2 + \\\\beta_{22}x_2^2 + \\\\beta_{12}x_1x_2 + error\\\\)\\n**linear effect params are \\\\(\\\\beta_1, \\\\beta_2\\\\)\\n**Quadratic effect params are \\\\(\\\\beta_{11}, \\\\beta_{22}\\\\)\\n**Interaction effect params are \\\\(\\\\beta_{12}\\\\)\\n*There are still linear models, regressors incorporate nonlinear effect into linear relationship\\n*Direction = sign of coefficient of highest order\\n**This is the curvature\\n*We want less regressors unless adds a lot of value to have more\",\"code\":{}}"], ["Lecture 2/21", "{\"input\":\"<h1>Model Fitness vs Model Complexity</h1>\\n<hr>\\n*RSS  of \\\\(R^2\\\\) is unexplained variation, not appropriate for model complexity\\n**Important: (larger/smaller)? RSS means the model fits the sample data better\\n**Important: larger \\\\(R^2\\\\) means the model fits the sample data better\\n*k (the number of regressors) measures model complexity\\n**Smaller k means model is simpler\\n**All regressors related to one categorical var will only count once\\n<h2>Criteria needed to consider both model fitness and complexity</h2>\\n<hr>\\n*The adjusted \\\\(R^2\\\\)\\n**\\\\(R^2_{adj} = 1 - \\\\frac{RSS / (n-k)}{SST / (n-1)}\\\\)\\n*Akaike's Information Criterion (AIC)\\n**\\\\(AIC = nlog(\\\\frac{RSS}{n}) + 2k\\\\) (log is natural log)\\n**You want to select model with lowest AIC\\n**In R:cod:r,aic\\n*Bayesian Information Criteria (BIC)\\n**\\\\(AIC = nlog(\\\\frac{RSS}{n}) + log(n)k\\\\) (log is natural log)\\n**You want lowest BIC\\n**R code: cod:r,bic\\n<h2>Selection Method</h2>\\n<hr>\\n*All-subsets selection: considering every model within the scope\\n**Can have \\\\(2^p\\\\) subsets. P is number of predictors\\n**This is very thorough, but computationally expensive\\n*Stepwise method:\\n**Backward elimination with AIC\\n***Select model through each step by \",\"code\":{\"aic\":\"extractAIC(ModelName)\",\"bic\":\"extractAIC(ModelName, k = log(n) )  \"}}"], ["ANOVA", "{\"input\":\"<h1>One Way ANOVA</h1>\\n*Comparison among three or more groups of data\\n*Compares the variance in the group means within a sample whilst considering only one independent variable or factor\\n*Explanatory factor is groupings\\n*Treatment and level are same\\n*Balanced when each group has same number of units\\n*Null is all equal, alternate is at least one not equal\\n*For I groups, I - 1 df\\n*Assumptions are:\\n**Normality\\n**Sample Independence\\n**Variance Equality\\n**Dependent vars continuous\\n*Tukey HSD can be used to find where groups differ\\n**cod:r,tujey\\n*If residuals vs fitted has pattern, might be other predictors not accounted for\\n*Flat scale location line means equal variances\\n*Can use shapiro-wilk test for normality. If null not rejected then normal\\n**cod:r,shap\\n*Homogeneity Tests\",\"code\":{\"tujey\":\"TukeyHSD(mod, conf.level=0.99)\\n# for disgnostics do\\nplot(mod)\",\"shap\":\"shapiro.test(resid(mod))\"}}"], ["Lecture 2/28", "{\"input\": \"\", \"code\": {}}"], ["Chapter 3 and 4", "{\"input\":\"<h1>Multiple Linear Regression</h1>\\n*Interpret coeffcient as if only one var is changing\\n*Partial F test is anova(smaller, larger)\\n*Model selection:\\n**Want model with lowest aic\\n**For BIC do extractAIC(ModelName, k = log(n) )  \\n\\nInclude in notes:\\n*F stat\\n*Intervals\\n\",\"code\":{}}"], ["Lecture 3/2", "{\"input\":\"<h2>Estimation of Model</h2>\\n<hr>\\ncod:r,aov\\n*When p < 0.05, then reject \\\\(H_o\\\\) that all equal\\n*Multiple comparison shows what pairs differ\\n**Use Tukey's HSD test\",\"code\":{\"aov\":\"model1 <- aov(Mileage~Brands)\\nsummary(model1)\\n#To find which ones differ\\nTukeyHSD(model1, conf.level=0.99)\"}}"], ["Midterm 1", "{\"input\":\"<h2>Four step process:</h2>\\n<hr>\\n1. Choose a from for model\\n2. Fit model\\n3. Assess how well model fits data\\n4. Use model to address question\\n<h2>Linear model</h2>\\n<hr>\\n*coefficients are \\\"on average\\\" in interpretation\\n*hat is used for estimated val\\n*\\\\(\\\\hat{\\\\beta_0}\\\\) is intercept estimator, \\\\(\\\\hat{\\\\beta_1}\\\\) is slope estimator\\n*Assumptions are:\\n**Linearity\\n***Look for lack if pattern in residual plot\\n***hist() in R\\n**Independence\\n**Normality\\n**Equal variance\\n***Can be proven with residual plot\\nOutlier vs High Leverage Point:\\n*Outlier is extreme, observation doesn'\\\\(\\\\)t fit pattern\\n*High leverage is extreme x, potential to have large influence on model\\n** \\\\(h_{ii} = \\\\frac{1}{n} + \\\\frac{(x_i - \\\\bar{x})^2}{SXX}\\\\)\\n*Standard residual: \\\\(r_i = \\\\frac{\\\\hat{e_i}}{\\\\hat{\\\\sigma}\\\\sqrt{1 - h_{ii}}}\\\\)\\n**If greater than 3 outlier\\n**cod:r,str\\n*Cook's Distance: \\\\(D_i = \\\\frac{r_i^2}{2} \\\\frac{h_{ii}}{1 - h_{ii}}\\\\)\\n**Investigate D > 1\\n**cod:r,cook\\n<h2>Scatter Plot</h2>\\n<hr>\\ncod:r,scat\\n<h2>Transformations</h2>\\n<hr>\\n*Power transformation \\\\(W \\\\implies W^{\\\\lambda} \\\\lambda \\\\neq 0, log(W) \\\\lambda = 0\\\\)\\n*Box-Cox Transformation: Commonly used to make more normally distributed\\n**\\\\(y(\\\\lambda) = \\\\frac{(y^{\\\\lambda}-1)}{\\\\lambda}\\\\) if \\\\(y \\\\neq 0\\\\)\\n**\\\\(y(\\\\lambda) = log(y)\\\\) if \\\\(y=0\\\\)\\n**In R: cod:r,boxcox\\n<h2>t Test for Slope</h2>\\n<hr>\\n*Hypothesis:\\n**\\\\(H_o: \\\\beta_1 = 0\\\\)\\n**\\\\(H_a: \\\\beta_1 \\\\neq 0\\\\)\\n*Test stat: \\\\(t = \\\\frac{b_1 - \\\\beta_1}{S_{b_1}}\\\\) where \\\\(S_{b_1} =\\\\frac{S_{YX}}{\\\\sqrt{\\\\sum_{i=1}^{n} (X_i - \\\\bar{X})^2}}\\\\)\\n**df = n - 2 \\n*Confidence interval of regression coefficients\\n**In R: cod:r,confint\\n<h2>F Test for Slope</h2>\\n<hr>\\n*Test stat: \\\\(F = \\\\frac{SSreg}{\\\\frac{RSS}{n-2}}\\\\) numerator has df = 1, denominator has df = n-2\\n*Standard error of regression is typical error and is  \\\\(\\\\sqrt{\\\\frac{SSE}{n-2}}\\\\)\\n<h2>t Test for Correlation</h2>\\n<hr>\\n*Test stat: \\\\(t = \\\\frac{r - p}{\\\\sqrt{\\\\frac{1-r^2}{n-2}}}\\\\)\\n*In R: cod:r,cor\\n*\\\\(r = \\\\frac{ \\\\sum_{i=1}^n (X_i-\\\\bar{X}) (Y_i-\\\\bar{Y} }{\\\\sqrt{\\\\sum_{i=1}^n (X_i-\\\\bar{X})^2 \\\\sum_{i=1}^n (Y_i-\\\\bar{Y})^2}}\\\\)\\n*Use multiple r\\n<h2>More Error Notes</h2>\\n<hr>\\n*\\\\(F = \\\\frac{MSModel}{MSE}, MSE=\\\\frac{SSE}{n-2}\\\\)\\n*F Test checks if slope is significant\\n*\\\\(r^2 = 1- \\\\frac{SSE}{SSTotal}\\\\)\\n*\\\\(Slope = r\\\\frac{S_y}{S_x}\\\\)\\n*Can test r with t test\\n**\\\\(t = \\\\frac{r\\\\sqrt{n-2}}{\\\\sqrt{1-r^2}}\\\\)\\n**n-2 degrees of freedom\\n**\\\\(\\\\rho = 0\\\\) is null where \\\\(\\\\rho\\\\) is population correlation\\n*Practically vs Statistically Significant\\n*Confidence interval: \\\\(\\\\hat{y} \\\\pm t*SE_{\\\\hat{\\\\mu}}\\\\)\\n*Prediction interval: \\\\(\\\\hat{y} \\\\pm t*SE_{\\\\hat{y}}\\\\)\\n*t* is the critical value n-2 degrees of freedom\\n*Residual Standard error is square root of (RSS / n - 2)\\n<h2>Decomposing Variability</h2>\\n<hr>\\n*SST = tot al variation in Y df = n-1\\n*SSreg = variation in y explained by model df = 1\\n*RSS = Variation unexplained by model df = n - 2\\n<h2>Other Notes</h2>\\n<hr>\\n*to load data in R: cod:r,load\\n*To setup categorical vars in R: cod:r,cat\\n*Predict: cod:r,pred\",\"code\":{\"lm\":\"\\n\",\"scat\":\"plot(x,y, main=\u201c Scatter Plot of Y against X\u201d, data=INDEX)\\r\\nabline(lm(y~x), data=INDEX)\",\"str\":\"StdResid <- rstandard(model)\",\"cook\":\"cooksD <- cooks.distance(model)\\r\\ninfluential <- cooksD[(cooksD > (3 * mean(cooksD, na.rm = TRUE)))]\",\"boxcox\":\"library(MASS) \\n#create data \\ny=c(1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 6, 7, 8) \\nx=c(7, 7, 8, 3, 2, 4, 4, 6, 6, 7, 5, 3, 3, 5, 8) \\n#fit linear regression model \\nmodel <- lm(y~x)\\n#find optimal lambda for Box-Cox transformation\\nbc <- boxcox(y ~ x) (lambda <- bc$x[which.max(bc$y)]) \\n[1] -0.4242424 \\n#fit new linear regression model using the Box-Cox transformation \\nnew_model <- lm(((y^lambda-1)/lambda) ~ x) \",\"confint\":\"confint(model,level=0.95)\\n#by hand 95% level for Experience squared\\nalpha <- 0.05\\nbeta <- -0.053316\\nse <- 0.002477\\nbeta + c(-1,1)*qt(1-alpha/2,df=140)*se\",\"cor\":\"cor_test <- cor.test(x, y, method = \\\"pearson\\\")\",\"load\":\"library(\\\"Stat2Data\\\")\\ndata(\\\"Cereal\\\")\\nattach(Cereal)\",\"cat\":\"Kids198$Sex <- as.factor(Kids198$Sex)\",\"pred\":\"predict(mod, data.frame(BodySize=1))\"}}"], ["Midterm 2", "{\"input\":\"<h2>Multiple Variables</h2>\\n<hr>\\n*Prediction intervals cod:r,pred\\n*: is interaction\\n*To look at pairwise relationships cod:r,pair\\n*Nested f test: \\n**Null hypoth is that small model is as good as big model. Sig = big model better\\n**do anova(smaler, larger) for linear models\\n*av plots can be used to show different single var linear relationships cod:r,av\\n*To find bets model cod:r,regs\\n*Can also use AIC, select lowest cod:r,aic\\n**for forward selection start with smallest model, opposite for backward selection. Change first param\\n**BIC is similar but k = log(nrow(dataset)) rather than 2\\n\\n<h2>ANOVA</h2>\\n*Use aov cmd\\n*To look for interaction parallel means no interaction cod:r,inter\\\\\\n*aov(y~x1*x2) does interaction model\\n*plot(mod) to check assumptions\\n*Can do nested f test with anova() too\\n*Tukey cod:r,tuk\\n*Assumptions are:\\n**Normality\\n**Sample Independence\\n**Variance Equality\\n**Dependent vars continuous\\n\\n<h2>General Notes:</h2>\\n<hr>\\n*cod:r,f\\n*SST = tot al variation in Y df = n-1\\n*SSreg = variation in y explained by model df = 1\\n*RSS = Variation unexplained by model df = n - 2\\n*Residual Standard error is square root of (RSS / n - 2)\",\"code\":{\"pred\":\"new.data <- data.frame(PointsFor=400,PointsAgainst=200)\\npredict(Mod.1,new.data,interval = \\\"confidence\\\")\\npredict(Mod.1,new.data,interval = \\\"prediction\\\")\",\"f\":\"as.factor(data$var)\",\"pair\":\"pairs(~Weight+Width+Length)\",\"av\":\"avPlots(lm)\",\"regs\":\"library(leaps)\\nfull <- lm(GPA ~ .,data=GPA.df)\\nregs <- regsubsets(GPA~.,data=GPA.df,nvmax=6)\",\"aic\":\"full <- lm(GPA ~ .,data=GPA.df)\\nint <- lm(GPA~1,data=GPA.df)\\nstepAIC(int,scope=list(lower=int,upper=full),direction=\\\"forward\\\",trace=1,k=2)\",\"inter\":\"interaction.plot(Antibiotics,B12,WgtGain)\",\"inter\\\\\":\"interaction.plot(Antibiotics,B12,WgtGain)\",\"tuk\":\"TukeyHSD(mod, conf.level=0.99)\"}}"], ["Lecture 4/6", "{\"input\":\"*Ordinal Response: Ex: level of agreement. It must be ordered\\n*Chi-Squared test cod:r,chi\",\"code\":{\"chi\":\"dt <- rbind(c(29,22), c(61,78))\\nchisq.test(dt, correct=FALSE)\"}}"], ["Lecture 4/4", "{\"input\":\"*Analysis of Covariance using categorical and quantitative\\n*Linear probability model (LPM) is a regression where the outcome is a binary value\\n**Ie outcome is categorical\\n*Multinomial is more than two outcomes\\n*logit form \\\\(log(\\\\frac{\\\\pi}{1-\\\\pi}) = \\\\beta_0 + \\\\beta_1X \\\\)\\n*Probability form: \\\\(\\\\pi = \\\\frac{e^{\\\\beta_0 + \\\\beta_1X}}{1 + e^{\\\\beta_0 + \\\\beta_1X}}\\\\)\\n*cod:r,glm\\n*Z value is output\\n*logit form \\\\(log(\\\\frac{\\\\hat{y}}{1-\\\\hat{y}})\\\\)\",\"code\":{\"glm\":\"mod <- glm(y~x, family=\\\"binomial)\\nsummary(mod)\\nconfint(mod)\"}}"], ["Lecture 4/8", "{\"input\":\"Likelihood Ratio Test\\n*-2log(L) is the residual deviance\\n*\\\\(G = -2log(L_o)-(-2log(L))\\\\)\\n*\\\\(H_o\\\\) is reduced model\\n*\\\\(H_a is full model\\\\)\\n*cod:r,lrt\\n\",\"code\":{\"lrt\":\"pchisq(G, df=1, lower.tail=FALSE)\"}}"]], "test": [["test2", "{\"input\":\"cod:python,a\\n\\ncod:python,b\",\"code\":{\"b\":\"test\"}}"]]}